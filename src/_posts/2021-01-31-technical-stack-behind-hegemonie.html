---
Title: The Technical Stack
Date: 2021-01-31
Keywords: |
  hegemonie, game engine, online rpg, stragey game, diplomacy game, game master,
  golang, micro services, observability, opentelemetry, prometheus
Description: |
  The game engine will following the architectural best practices since day 0.
---
<%inherit file="blog"/>

<h3>API First!</h3>
<p>
  Tens of years of evolution in IT teach us that the boundaries and the
  interactions between the parts of a system are a key part of the
  design of a program. Not only is the efficiency in question but more
  important is the ability to maintain the program. Each part of the system
  is exposed to the others via its API.
</p>
<p>
  Let's be honest: designing a good user interface requires different skills
  than designing a good backend. I have no recent UI skill, and designing a UI
  would end in server-side generated HTML pages. Instead, I dedicate my time to
  the backend: a well-design set of interconected services, each exposing a
  clean API with the proper instrumentation to secure and observe it.
</p>

<h3>Micro-services architecture</h3>
<p>
  My personal conviction leads me to split the system into isolated services (where
  a "service" stands for a set of network processes serving its API). Despite the
  burden of maintaining connections between the services, the latency introduced
  in the communications, it opens the door to a per-service scalability and
  instrumentation.
</p>
<p>
  All the backend code is written in ${link("https://golang.org","Golang")}.
  ${link("https://grpc.io","gRPC")} is the middleware shared by all our microservices.
</p>
<p>
  The persistence of the data for each service currently depend on the type of service:
</p>
<ul>
  <li>
    maps: the local filesystem is currently used, with one file per map.
    There are plans to locate the maps on an Object Storage platform.
  </li>
  <li>
    events: a local ${link("https://github.org/jfsmig/rocksdb","RocksDB")} database is currently used.
    There are plans for a ${link("https://tikv.org/","TiKV")} storage.
  </li>
  <li>
    region: a local file system is currently used.
    There are plans for a ${link("https://tikv.org/","TiKV")} storage.
  </li>
</ul>

<h3>Observability at the core</h3>
<p>
  The fine-grained observability of the execution of the RPC calls is allowed by
  ${link("https://opentelemetry.io","OpenTelemetry")}. Traces are generated in a
  side-car agent. By default, the sandbox installation proposes an all-in-one
  installation with its own Prometheus storage and a dashboard.
</p>

<h3>Best-in-class Authorization &amp; Authentiation</h3>
<p>
  The ${link("https://www.ory.sh","ORY")} suite is used for the AAA purpse.
  At the gate, a ${link("https://haproxy.org","HAProxy")} enforces the security policy
  with the help of a ${link("","ORY OathKeeper")}.
  OpenID Connect is used for the Authentication via ${link("https://www.ory.sh/hydra/","ORY Hydra")}.
  A local user registry is available thanks to ${link("https://www.ory.sh/kratos/","ORY Kratos")}, as a source for ORY Hydra.
  The authorization of the users on their cities is achieved with ${link("https://www.ory.sh/keto/","ORY Keto")}. 
  The security is enforced at the gate, in the API micro-service that requires valid
  ${link("https://jwt.io","JSON Web Tokens")} for each RPC.
</p>

<h3>Monitoring</h3>
<p>
  The monitoring of the platform is achieved with
  ${link("https://prometheus.io","Prometheus")}. A set of exporters is in place for
  the gRPC services.
</p>
<p>
  The monitoring of the hosts is achieved via ${link("https://www.netdata.cloud","NetData")}.
  No data from Netdata is centralized in Prometheus.
</p>
